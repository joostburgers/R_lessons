interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
radar_facet <- entities_matches_sentiment %>%
select(-positive,-negative,-sentiment) %>% #drop out the unnecessary columns
filter(kind == "person") %>%
group_by(title, entity, kind) %>%
summarise(across(anger:trust, sum)) %>%
mutate(total = rowSums(across(where(is.numeric))))  %>%
arrange(desc(total)) %>%
head(5)  %>% #Change number to include more or fewer entities
mutate(across(anger:trust, .fns = ~ round((. / total) * 100))) %>%
select(-total, -kind)
ggRadar(
data = radar_facet,
mapping = aes(color = title, facet = entity),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
radar_facet_sentiment <- entities_matches_sentiment %>%
#Change filter to locations for locations
filter(kind == "person") %>%
group_by(title, entity, kind) %>%
summarise(across(anger:sentiment, sum)) %>%
arrange(desc(sentiment))  %>%
tail(5)  %>% #Change number to include more or fewer entities
select(-positive,-negative,-sentiment,-kind)
ggRadar(
data = radar_facet_sentiment,
mapping = aes(color = title, facet = entity),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
corpus <- gutenberg_download(c(786,1400),meta_fields = c("author","title"))
corpus <- gutenberg_download(c(1400,98), mirror="http://mirrors.xmission.com/gutenberg/", meta_fields = c("author","title"))
corpus_clean <- corpus %>%
filter(text!="") %>%
mutate(text = str_replace_all(text,"_"," "))
corpus_text <- corpus_clean %>%
group_by(title) %>%
mutate(text = paste(as.character(text), collapse = " ")) %>%
distinct() %>%
ungroup()
corpus_text_str <- corpus_text %>%
group_by(title) %>%
mutate(text = list(as.String(text)))
#set pipeline
wordAnnotator <- Maxent_Word_Token_Annotator(language = "en")
sentenceAnnotator <- Maxent_Sent_Token_Annotator(language = "en")
characterAnnotatorEN <- Maxent_Entity_Annotator(language = "en", kind = "person")
locationAnnotatorEN <- Maxent_Entity_Annotator(language = "en", kind = "location")
pipeline <- list(sentenceAnnotator,
wordAnnotator,
characterAnnotatorEN,
locationAnnotatorEN)
#create empty df
full_df = as.data.frame(NULL)
chunk_size = 10000
for (j in 1:nrow(corpus_text_str)) {
#get number of chunks
chunk <- nchar(corpus_text_str$text[j]) %/% chunk_size
text <- unlist(corpus_text_str$text[j])
text <- as.String(text)
#Loop runs through the text section by section and reads each chunk into a df
for (i in 1:chunk) {
print(paste0(
"Processing title: ",
corpus_text_str$title[j],
" - section ",
i,
" of ",
chunk
))
temp_df = NULL
if (i == 1) {
m = 1
}
if (i == chunk) {
m = n + 1
n = (nchar(text))
}
else{
n <- m + chunk_size
}
temp_string = text[m, n]
temp_ann <- NLP::annotate(temp_string, pipeline)
temp_df <-  temp_ann %>%
as.data.frame %>%
filter(type != "word")
temp_df <- temp_df %>%
mutate(words = str_sub(
as.character(temp_string),
start = temp_df$start,
end = temp_df$end
)) %>%
unnest_wider(features)
temp_df <- temp_df %>%
mutate(author = corpus_text_str$author[j], title = corpus_text_str$title[j])
#This is where you would include your added variable
#stitch it all together
full_df <- full_df %>%
bind_rows(temp_df)
m <- m + chunk_size
}
}
full_df_backup <- full_df
library(textclean)
corpus_clean <- corpus %>%
filter(text!="") %>%
mutate(text = str_replace_all(text,"_"," ")) %>%
mutate(text = replace_contraction(text)) %>%
mutate(text = replace_curly_quote(text))
corpus_text <- corpus_clean %>%
group_by(title) %>%
mutate(text = paste(as.character(text), collapse = " ")) %>%
distinct() %>%
ungroup()
corpus_text_str <- corpus_text %>%
group_by(title) %>%
mutate(text = list(as.String(text)))
#set pipeline
wordAnnotator <- Maxent_Word_Token_Annotator(language = "en")
sentenceAnnotator <- Maxent_Sent_Token_Annotator(language = "en")
characterAnnotatorEN <- Maxent_Entity_Annotator(language = "en", kind = "person")
locationAnnotatorEN <- Maxent_Entity_Annotator(language = "en", kind = "location")
pipeline <- list(sentenceAnnotator,
wordAnnotator,
characterAnnotatorEN,
locationAnnotatorEN)
#create empty df
full_df = as.data.frame(NULL)
chunk_size = 10000
for (j in 1:nrow(corpus_text_str)) {
#get number of chunks
chunk <- nchar(corpus_text_str$text[j]) %/% chunk_size
text <- unlist(corpus_text_str$text[j])
text <- as.String(text)
#Loop runs through the text section by section and reads each chunk into a df
for (i in 1:chunk) {
print(paste0(
"Processing title: ",
corpus_text_str$title[j],
" - section ",
i,
" of ",
chunk
))
temp_df = NULL
if (i == 1) {
m = 1
}
if (i == chunk) {
m = n + 1
n = (nchar(text))
}
else{
n <- m + chunk_size
}
temp_string = text[m, n]
temp_ann <- NLP::annotate(temp_string, pipeline)
temp_df <-  temp_ann %>%
as.data.frame %>%
filter(type != "word")
temp_df <- temp_df %>%
mutate(words = str_sub(
as.character(temp_string),
start = temp_df$start,
end = temp_df$end
)) %>%
unnest_wider(features)
temp_df <- temp_df %>%
mutate(author = corpus_text_str$author[j], title = corpus_text_str$title[j])
#This is where you would include your added variable
#stitch it all together
full_df <- full_df %>%
bind_rows(temp_df)
m <- m + chunk_size
}
}
full_df_backup <- full_df
full_df <-  full_df %>%
mutate(words = str_remove_all(words, '[:punct:]'))
full_df <- full_df %>%
relocate(c("author","title"),.before = 1) %>%
select(-id, -constituents)
write.csv(full_df, "annotation_backup.csv")
full_df <- read.csv("annotation_backup.csv", stringsAsFactors = FALSE)
df1 <- full_df %>%
filter(type == "sentence") %>%
mutate(sentence_nr = row_number()) %>%
select(author, title, words, sentence_nr) %>%
rename(sentence = words)
df2 <-  full_df %>%
filter(type == "entity") %>%
mutate(record = row_number()) %>%
select(words, kind)
df2 <- df2 %>%
mutate(words = str_replace_all(words, "Dear ", "")) %>%
mutate(words = str_replace_all(words, "Young ", "")) %>%
mutate(words = str_replace_all(words, "Ah", "")) %>%
mutate(words = str_replace_all(words, "Oh", "")) %>%
mutate(words = str_trim(words, side= "both")) %>%
mutate(words = str_trim(gsub("[A-Z]{2,}","",words))) %>%
mutate(words = str_squish(words)) %>%
mutate_all(~ifelse(. %in% c("N/A", "null", ""), NA, .)) %>%
drop_na() %>%
dplyr::filter(nchar(words) > 2) %>%
distinct()
capital_stopwords <- as.data.frame(str_to_title(stop_words$word)) %>%
rename(words= 1)
df2 <- df2 %>%
anti_join(capital_stopwords)
pre_join <- pre_join %>%
select(words, kind) %>%
drop_na()  %>%
distinct()
write.csv(df2, "pre_join_entities.csv")
#Prep the data
pre_join <- read_csv("pre_join_clean_entities.csv", na = "NA")
pre_join <- pre_join %>%
select(words, kind) %>%
drop_na()  %>%
distinct()
#Execute a SQL query
full_join_df <- sqldf("SELECT *
FROM df1
LEFT JOIN pre_join ON df1.sentence LIKE '%' || pre_join.words || '%'")
full_join_df <- full_join_df %>%
distinct()
View(full_join_df)
write_csv(full_join_df, "entities_raw.csv")
View(pre_join)
#Prep the data
pre_join <- read_csv("pre_join_entities_clean.csv", na = "NA")
View(pre_join)
#Execute a SQL query
full_join_df <- sqldf("SELECT *
FROM df1
LEFT JOIN pre_join ON df1.sentence LIKE '%' || pre_join.words || '%'")
full_join_df <- full_join_df %>%
distinct()
View(full_join_df)
write_csv(full_join_df, "entities_raw.csv")
full_join_df <- full_join_df %>%
distinct()
View(full_join_df)
View(full_join_df)
full_join_df <- full_join_df %>%
distinct() %>%
drop_na(words)
write_csv(full_join_df, "entities_raw.csv")
write_csv(full_join_df, "entities_raw.csv")
clean_entities <- read.csv("entities_cleaned.csv")
entities_unnest <- clean_entities %>%
unnest_tokens(word, sentence)
entities_unnest <- entities_unnest %>%
anti_join(stop_words)
#create sentiment table
entities_sentiment <- entities_unnest %>%
group_by(author, title) %>%
inner_join(get_sentiments("nrc")) %>%
count(sentence_nr, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
entities_matches_sentiment <- entities_matches_sentiment %>%
rename(entity = words)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, entity, kind) %>%
summarise(total = mean(sentiment))
View(ner_total_sentiment)
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(10) %>%
mutate(entity = reorder(entity, total)) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(-10) %>%
mutate(entity = reorder(entity, (desc(total)))) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
clean_entities <- read.csv("entities_cleaned.csv")
entities_unnest <- clean_entities %>%
unnest_tokens(word, sentence)
entities_unnest <- entities_unnest %>%
anti_join(stop_words)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
entities_matches_sentiment <- entities_matches_sentiment %>%
rename(entity = words)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, entity, kind) %>%
summarise(total = mean(sentiment))
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(10) %>%
mutate(entity = reorder(entity, total)) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
clean_entities <- read.csv("entities_cleaned.csv")
entities_unnest <- clean_entities %>%
unnest_tokens(word, sentence)
entities_unnest <- entities_unnest %>%
anti_join(stop_words)
#create sentiment table
entities_sentiment <- entities_unnest %>%
group_by(author, title) %>%
inner_join(get_sentiments("nrc")) %>%
count(sentence_nr, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
entities_matches_sentiment <- entities_matches_sentiment %>%
rename(entity = words)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, entity, kind) %>%
summarise(total = mean(sentiment))
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(10) %>%
mutate(entity = reorder(entity, total)) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(-10) %>%
mutate(entity = reorder(entity, (desc(total)))) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
clean_entities <- read.csv("entities_cleaned.csv")
entities_unnest <- clean_entities %>%
unnest_tokens(word, sentence)
entities_unnest <- entities_unnest %>%
anti_join(stop_words)
#create sentiment table
entities_sentiment <- entities_unnest %>%
group_by(author, title) %>%
inner_join(get_sentiments("nrc")) %>%
count(sentence_nr, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
entities_matches_sentiment <- entities_matches_sentiment %>%
rename(entity = words)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, entity, kind) %>%
summarise(total = mean(sentiment))
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(10) %>%
mutate(entity = reorder(entity, total)) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(-10) %>%
mutate(entity = reorder(entity, (desc(total)))) %>%
ggplot(aes(entity, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
radar_facet <- entities_matches_sentiment %>%
select(-positive,-negative,-sentiment) %>% #drop out the unnecessary columns
filter(kind == "person") %>%
group_by(title, entity, kind) %>%
summarise(across(anger:trust, sum)) %>%
mutate(total = rowSums(across(where(is.numeric))))  %>%
arrange(desc(total)) %>%
head(5)  %>% #Change number to include more or fewer entities
mutate(across(anger:trust, .fns = ~ round((. / total) * 100))) %>%
select(-total, -kind)
ggRadar(
data = radar_facet,
mapping = aes(color = title, facet = entity),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
radar_facet_sentiment <- entities_matches_sentiment %>%
#Change filter to locations for locations
filter(kind == "person") %>%
group_by(title, entity, kind) %>%
summarise(across(anger:sentiment, sum)) %>%
arrange(desc(sentiment))  %>%
tail(5)  %>% #Change number to include more or fewer entities
select(-positive,-negative,-sentiment,-kind)
ggRadar(
data = radar_facet_sentiment,
mapping = aes(color = title, facet = entity),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
#create sentiment table
entities_sentiment <- entities_unnest %>%
group_by(author, title) %>%
inner_join(get_sentiments("nrc")) %>%
count(sentence_nr, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
View(entities_sentiment)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
View(entities_matches_sentiment)
View(entities_matches_sentiment)
entities_matches_sentiment <- entities_unnest %>%
inner_join(entities_sentiment) %>%
distinct_at(vars(-word))
View(entities_matches_sentiment)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, entity, kind) %>%
summarise(total = mean(sentiment))
View(entities_matches_sentiment)
ner_total_sentiment <- entities_matches_sentiment %>%
group_by(author, title, words, kind) %>%
summarise(total = mean(sentiment))
View(ner_total_sentiment)
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(10) %>%
mutate(words = reorder(words, total)) %>%
ggplot(aes(words, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
ner_total_sentiment %>%
group_by(title) %>%
filter(kind == "person") %>%
top_n(-10) %>%
mutate(words = reorder(words, (desc(total)))) %>%
ggplot(aes(words, y = total, fill = title)) +
geom_col() +
facet_wrap( ~ title, scales = "free") +
coord_flip()
radar_facet <- entities_matches_sentiment %>%
select(-positive,-negative,-sentiment) %>% #drop out the unnecessary columns
filter(kind == "person") %>%
group_by(title, words, kind) %>%
summarise(across(anger:trust, sum)) %>%
mutate(total = rowSums(across(where(is.numeric))))  %>%
arrange(desc(total)) %>%
head(5)  %>% #Change number to include more or fewer entities
mutate(across(anger:trust, .fns = ~ round((. / total) * 100))) %>%
select(-total, -kind)
ggRadar(
data = radar_facet,
mapping = aes(color = title, facet = words),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
radar_facet_sentiment <- entities_matches_sentiment %>%
#Change filter to locations for locations
filter(kind == "person") %>%
group_by(title, words, kind) %>%
summarise(across(anger:sentiment, sum)) %>%
arrange(desc(sentiment))  %>%
tail(5)  %>% #Change number to include more or fewer entities
select(-positive,-negative,-sentiment,-kind)
ggRadar(
data = radar_facet_sentiment,
mapping = aes(color = title, facet = words),
rescale = FALSE,
interactive = TRUE,
use.label = TRUE,
size = 2,
legend.position = "right"
)
